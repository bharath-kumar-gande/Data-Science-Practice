{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing, decomposition, tree, model_selection, ensemble\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(59381, 128)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/Users/bharath/Desktop/Folder/Data Science/Projects/prudential-life-insurance-assessment/train.csv')\n",
    "test_data = pd.read_csv('/Users/bharath/Desktop/Folder/Data Science/Projects/prudential-life-insurance-assessment/test.csv')\n",
    "\n",
    "total_data = pd.concat([train_data, test_data])\n",
    "train_data.shape\n",
    "#print(total_data)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59381 entries, 0 to 59380\n",
      "Columns: 128 entries, Id to Response\n",
      "dtypes: float64(18), int64(109), object(1)\n",
      "memory usage: 58.0+ MB\n",
      "D3    18753\n",
      "D4    14071\n",
      "A8     9140\n",
      "D1     8611\n",
      "D2     8344\n",
      "E1     3711\n",
      "A1     3219\n",
      "A2     3072\n",
      "A6     2733\n",
      "A7     1823\n",
      "A3     1564\n",
      "B2     1446\n",
      "A5     1009\n",
      "C3      437\n",
      "C1      377\n",
      "C4      291\n",
      "A4      263\n",
      "C2      197\n",
      "B1       85\n",
      "Name: Product_Info_2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "total_data.shape\n",
    "train_data.info()\n",
    "total_data1 = total_data.drop(['Product_Info_2','Medical_History_1', 'Medical_History_10', 'Medical_History_15', 'Medical_History_24', 'Medical_History_32'], axis=1)\n",
    "total_data1.shape\n",
    "print(total_data['Product_Info_2'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for numeric and chategorical columns\n",
    "#previous_num_columns = total_data1.select_dtypes(exclude=['object']).columns.values.tolist()\n",
    "#print(previous_num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "Imputer = preprocessing.Imputer(strategy='mean')\n",
    "Imputer.fit(total_data1)\n",
    "X = Imputer.transform(total_data1)\n",
    "total_data_tr = pd.DataFrame(X, columns=total_data1.columns)\n",
    "#total_missing = total_data_tr.isnull().any().sum()\n",
    "#print(total_missing)\n",
    "#X.shape\n",
    "y_impute = total_data_tr['Response']\n",
    "x_impute = total_data_tr.drop('Response',axis=1)\n",
    "y_train = y_impute[0:train_data.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "Scaler = preprocessing.StandardScaler()\n",
    "Scaler.fit(x_impute)\n",
    "X_scaled = Scaler.transform(x_impute)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns = x_impute.columns)\n",
    "X_scaled.shape\n",
    "total_missing1 = X_scaled_df.isnull().any().sum()\n",
    "print(total_missing1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79146, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = decomposition.PCA(n_components=10)\n",
    "pca.fit(X_scaled)\n",
    "x_transformed = pca.transform(X_scaled)\n",
    "x_transformed.shape\n",
    "#X_transformed = X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59381, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = x_transformed[0:train_data.shape[0]]\n",
    "X_train.shape\n",
    "X_test = x_transformed[train_data.shape[0]:]\n",
    "X_test.shape\n",
    "X_train.shape\n",
    "#total_data_X = pd.DataFrame(X_train, columns=total_data1.columns)\n",
    "#total_missing = total_data_tr.isnull().any().sum()\n",
    "#print(total_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt = tree.DecisionTreeClassifier()\n",
    "#dt_ada = ensemble.AdaBoostClassifier(dt,random_state=10)\n",
    "#ada_grid = {'n_estimators':[5, 8, 10, 12],'learning_rate':[0.1, 0.5, 0.9]}\n",
    "#param_grid = model_selection.GridSearchCV(dt_ada, ada_grid, cv=10, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt = tree.DecisionTreeClassifier()\n",
    "#-------\n",
    "#dt = ensemble.RandomForestClassifier(n_estimators=5)\n",
    "#-------\n",
    "dt = ensemble.RandomForestClassifier(random_state=5)\n",
    "dt_rand_grid = {'n_estimators':[40,50],'criterion':['gini','entropy'],'max_depth': [2,4,6],'min_samples_split':[2,5,8] }\n",
    "param_grid = model_selection.GridSearchCV(dt, dt_rand_grid, cv=5, n_jobs=5)\n",
    "#----------\n",
    "#param_grid = model_selection.GridSearchCV(dt, dt_rand_grid, cv=5, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=5, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=5,\n",
       "       param_grid={'n_estimators': [40, 50], 'criterion': ['gini', 'entropy'], 'max_depth': [2, 4, 6], 'min_samples_split': [2, 5, 8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3187383169700746"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42042067327933175"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = param_grid.best_estimator_\n",
    "final_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42042067327933175"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40988065587617467\n"
     ]
    }
   ],
   "source": [
    "cv_score = model_selection.cross_val_score(final_model, X_train, y_train, cv=15)\n",
    "print(cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Response'] = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data.to_csv(\"Prudential.csv\",columns=['Id','Survived'],index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
